{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CapstoneResourcePrediction.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNrCRsx0uw7ZsR9vckXBYeO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhuvaneshkj/Finops-Cloud-Tool/blob/Dev_Bhuvanesh/CapstoneResourcePrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q5s0z4NpwBl"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "try:\n",
        "  !pip install pystan\n",
        "  !pip install --upgrade git+https://github.com/jroakes/google-analytics.git\n",
        "  !pip install fbprophet\n",
        "  !pip install xgboost\n",
        "except:\n",
        "  pass\n",
        "finally:\n",
        "  clear_output()\n",
        "  print('All Loaded')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0J6zBAwqCF6"
      },
      "source": [
        "import pandas as pd\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtRv1oM8qCf1"
      },
      "source": [
        "from fbprophet import Prophet\n",
        "import seaborn as sns\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VrnlVJ4qFaH"
      },
      "source": [
        "df=  pd.read_csv('/content/ProcessedData.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5ohoATUVzJ1"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlMYIKF8qfVH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eA-LE1jaqnne"
      },
      "source": [
        "df = df.set_index(\"Time\")\n",
        "ax = df['CPU usage [%]'].plot(figsize = (16,5), title = \"CPU % Utilization\")\n",
        "ax.set(xlabel='Dates', ylabel='CPU usage [%]');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKgJ6QMkrn8y"
      },
      "source": [
        "df_pr_index = df.reset_index()\n",
        "df_pr_index.head()\n",
        "df_pr_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUgc_cNQquvQ"
      },
      "source": [
        "df['cap'] = 8.5\n",
        "df_pr = df_pr_index[['Time','CPU usage [%]']]\n",
        "\n",
        "df_pr.columns = ['ds','y'] # To use prophet column names should be like that\n",
        "train_data_pr = df_pr.iloc[:len(df)-20000]\n",
        "test_data_pr = df_pr.iloc[len(df)-20000:]\n",
        "m = Prophet()\n",
        "m.fit(train_data_pr)\n",
        "future = m.make_future_dataframe(periods=3,freq='MS')\n",
        "prophet_pred = m.predict(future)\n",
        "prophet_pred.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU168lNyZNSG"
      },
      "source": [
        "prophet_pred.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_UWZOhssrUv"
      },
      "source": [
        "fig1 = m.plot(prophet_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVgjIQkLtoVc"
      },
      "source": [
        "from fbprophet.plot import plot_plotly, plot_components_plotly\n",
        "\n",
        "plot_plotly(m, prophet_pred)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkcfjXaQveWw"
      },
      "source": [
        "m.plot_components(prophet_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANsqwE0EczNZ"
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "#mean_absolute_error(float(test_data_pr.iloc[len(test_data_pr)-5223:]), prophet_pred.yhat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9pH-3nwuA9u"
      },
      "source": [
        "\n",
        "# xgboost\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "print(\"xgboost\", xgb.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ssZa6HEu9ao"
      },
      "source": [
        "model = xgb.XGBRegressor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJPkstmnzkZ0"
      },
      "source": [
        "\n",
        "# transform a time series dataset into a supervised learning dataset\n",
        "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
        "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
        "\tdf = pd.DataFrame(data)\n",
        "\tcols = list()\n",
        "\t# input sequence (t-n, ... t-1)\n",
        "\tfor i in range(n_in, 0, -1):\n",
        "\t\tcols.append(df.shift(i))\n",
        "\t# forecast sequence (t, t+1, ... t+n)\n",
        "\tfor i in range(0, n_out):\n",
        "\t\tcols.append(df.shift(-i))\n",
        "\t# put it all together\n",
        "\tagg = pd.concat(cols, axis=1)\n",
        "\t# drop rows with NaN values\n",
        "\tif dropnan:\n",
        "\t\tagg.dropna(inplace=True)\n",
        "\treturn agg.values\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBaEagbWzkda"
      },
      "source": [
        "\n",
        "# walk-forward validation for univariate data\n",
        "def walk_forward_validation(data, n_test):\n",
        "\tpredictions = list()\n",
        "\t# split dataset\n",
        "\ttrain, test = train_test_split(data, n_test)\n",
        "\t# seed history with training dataset\n",
        "\thistory = [x for x in train]\n",
        "\t# step over each time-step in the test set\n",
        "\tfor i in range(len(test)):\n",
        "\t\t# split test row into input and output columns\n",
        "\t\ttestX, testy = test[i, :-1], test[i, -1]\n",
        "\t\t# fit model on history and make a prediction\n",
        "\t\tyhat = xgboost_forecast(history, testX)\n",
        "\t\t# store forecast in list of predictions\n",
        "\t\tpredictions.append(yhat)\n",
        "\t\t# add actual observation to history for the next loop\n",
        "\t\thistory.append(test[i])\n",
        "\t\t# summarize progress\n",
        "\t\tprint('>expected=%.1f, predicted=%.1f' % (testy, yhat))\n",
        "\t# estimate prediction error\n",
        "\terror = mean_absolute_error(test[:, -1], predictions)\n",
        "\treturn error, test[:, 1], predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sm8ARqQfzkjD"
      },
      "source": [
        "\n",
        "# split a univariate dataset into train/test sets\n",
        "def train_test_split(data, n_test):\n",
        "\treturn data[:-n_test, :], data[-n_test:, :]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyb2xIR_zkmR"
      },
      "source": [
        "\n",
        "# fit an xgboost model and make a one step prediction\n",
        "def xgboost_forecast(train, testX):\n",
        "\t# transform list into array\n",
        "\ttrain = np.array(train)\n",
        "\t# split into input and output columns\n",
        "\ttrainX, trainy = train[:, :-1], train[:, -1]\n",
        "\t# fit model\n",
        "\tmodel = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000)\n",
        "\tmodel.fit(trainX, trainy)\n",
        "\t# make a one-step prediction\n",
        "\tyhat = model.predict([testX])\n",
        "\treturn yhat[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mm03CDghzkpG"
      },
      "source": [
        "\n",
        "values = df1.values\n",
        "# transform the time series data into supervised learning\n",
        "data = series_to_supervised(values, n_in=6)\n",
        "# evaluate\n",
        "mae, y, yhat = walk_forward_validation(data, 12)\n",
        "print('MAE: %.3f' % mae)\n",
        "# plot expected vs preducted\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iywD_Rui9U7l"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(y, label='Expected')\n",
        "plt.plot(yhat, label='Predicted')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P-bVqSlzksP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZHvqwvpzkuw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bACUFTGzkyE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TATczBUKzk1K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pnEh9G4zkg0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaWg18jzvcFd"
      },
      "source": [
        " **Stationarity of a Time Series**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsQ2-43xvK12"
      },
      "source": [
        "A TS is said to be stationary if its statistical properties such as mean, variance remain constant over time. But why is it important? Most of the TS models work on the assumption that the TS is stationary. Intuitively, we can sat that if a TS has a particular behaviour over time, there is a very high probability that it will follow the same in the future. Also, the theories related to stationary series are more mature and easier to implement as compared to non-stationary series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LH67KR-bvW_j"
      },
      "source": [
        "df1=df[['Timestamp [ms]','CPU usage [%]']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l5thSivwqfB"
      },
      "source": [
        "df1.set_index('Timestamp [ms]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9yDTcI0yA-G"
      },
      "source": [
        "Dickey-Fuller Test: This is one of the statistical tests for checking stationarity. Here the null hypothesis is that the TS is non-stationary. The test results comprise of a Test Statistic and some Critical Values for difference confidence levels. If the ‘Test Statistic’ is less than the ‘Critical Value’, we can reject the null hypothesis and say that the series is stationary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJc_6MVuw2KF"
      },
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "def test_stationarity(timeseries):\n",
        "    \n",
        "    #Determing rolling statistics\n",
        "    rolmean = timeseries.rolling(window=12).mean()\n",
        "    rolstd = timeseries.rolling(window=12).std()\n",
        "\n",
        "    #Plot rolling statistics:\n",
        "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
        "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
        "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
        "    plt.legend(loc='best')\n",
        "    plt.title('Rolling Mean & Standard Deviation')\n",
        "    plt.show(block=False)\n",
        "    \n",
        "    #Perform Dickey-Fuller test:\n",
        "    print ('Results of Dickey-Fuller Test:')\n",
        "    dftest = adfuller(timeseries, autolag='AIC')\n",
        "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
        "    for key,value in dftest[4].items():\n",
        "        dfoutput['Critical Value (%s)'%key] = value\n",
        "    print(dfoutput)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bC5Emriaw-pt"
      },
      "source": [
        "test_stationarity(df1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrWJxq9byQSu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}